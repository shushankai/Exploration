{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a41370",
   "metadata": {},
   "source": [
    "# Weights and Bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa3e289",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics \n",
    "import wandb\n",
    "import ipywidgets\n",
    "import nbformat\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from  torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import Flowers102\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e1fb5",
   "metadata": {},
   "source": [
    "## CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795990bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGTH = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "BATCH_SIZE = 16\n",
    "HIDDEN_UNITS = 64\n",
    "EPOCH = 10\n",
    "\n",
    "CLASS_NAMES = np.array(Flowers102.classes)\n",
    "CLASS_LEN = len(CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a77ae",
   "metadata": {},
   "source": [
    "## MODEL CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199afe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_transform = transforms.Compose([\n",
    "    transforms.Resize([IMG_HEIGTH, IMG_WIDTH]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = Flowers102(\n",
    "    root=\"Data/train/\",\n",
    "    download= True, \n",
    "    transform= flower_transform, \n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "val_dataset = Flowers102(\n",
    "    root=\"Data/eval/\",\n",
    "    download= True, \n",
    "    transform= flower_transform, \n",
    "    split=\"val\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset= train_dataset, \n",
    "    batch_size= BATCH_SIZE , \n",
    "    num_workers= 0, \n",
    "    shuffle= True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset= val_dataset, \n",
    "    batch_size= BATCH_SIZE, \n",
    "    num_workers= 0, \n",
    "    shuffle= True\n",
    ")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# We will have 2 hidden layer neural netwrok \n",
    "class Modelv2(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_units ,bias=True, device=DEVICE):\n",
    "        super(Modelv2, self).__init__()\n",
    "        self.flaten = nn.Flatten()\n",
    "        self.layer_1 = nn.Linear(\n",
    "            in_features=in_features,\n",
    "            out_features= hidden_units, \n",
    "            bias= bias,\n",
    "            device= device\n",
    "        )\n",
    "        self.layer_2 = nn.Linear(\n",
    "            in_features=hidden_units,\n",
    "            out_features= out_features, \n",
    "            bias= bias,\n",
    "            device= device\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The below input is for only a single item from a batch\n",
    "        x = self.flaten(x)      Input: (224 ,224 ,3) -> Output: (224 * 224 * 3) \n",
    "        x = self.layer_1(x)     Input: (224 * 224 * 3) -> Output: hidden_units\n",
    "        x = self.relu(x)        Input: hidden_units -> Output: hidden_units\n",
    "        x = self.layer_2(x)     Input: hidden_units -> Output: 102 \n",
    "        \"\"\"\n",
    "        x = self.flaten(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "model = Modelv2(\n",
    "    in_features= IMG_CHANNELS * IMG_HEIGTH * IMG_WIDTH,\n",
    "    out_features= len(CLASS_NAMES), \n",
    "    hidden_units= HIDDEN_UNITS\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=0.5)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=CLASS_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(): \n",
    "    for epoch in tqdm(range(EPOCH)):\n",
    "        model.train()\n",
    "        loss_per_batch = []\n",
    "        print(f\"Epoch: {epoch}/{EPOCH}\")\n",
    "        for img, label in train_loader:\n",
    "            # load the data in DEVICE avliable\n",
    "            img, label = img.to(DEVICE), label.to(DEVICE)\n",
    "            \n",
    "            logits = model(img)\n",
    "            # print(torch.exp(logits)[2])\n",
    "            # print(torch.exp(logits).sum(dim=1).unsqueeze(1))\n",
    "            # print(torch.exp(logits).shape)\n",
    "            # probs = torch.exp(logits) / torch.exp(logits).sum(dim=1).unsqueeze(1)\n",
    "            # print(probs[0])\n",
    "            # print(torch.softmax(logits, dim=1)[0])\n",
    "            loss = loss_fn(logits, label)\n",
    "            loss_per_batch.append(loss)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        avg_loss = sum(loss_per_batch)/len(loss_per_batch)\n",
    "        print(f\"Average loss per batch: {avg_loss}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10468b79",
   "metadata": {},
   "source": [
    "## WANDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8c5a2",
   "metadata": {},
   "source": [
    "### HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874763c",
   "metadata": {},
   "source": [
    "* Epochs\n",
    "* Learning Rate\n",
    "* Batch size\n",
    "* Nodes in hidden Layers\n",
    "* Img h/w\n",
    "\n",
    "Weights and Biases (W & B) is a powerfull tool for: \n",
    "* Tracking experiments\n",
    "* Comparing model runs\n",
    "* hyperparameter sweeps \n",
    "* logging metrics, graidents, models and more \n",
    "\n",
    "It integrates easily with popular frameworks like Pytorch, Tnesorflow, Keras, HuggingFace, Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c2d613",
   "metadata": {},
   "source": [
    "**In pseudocode, what we'll do is:**\n",
    "\n",
    "```python\n",
    "# Import the library\n",
    "import wandb\n",
    "\n",
    "# start a new experiment \n",
    "wandb.init(project=\"my-project\")\n",
    "\n",
    "# capture a dictionary of hyperparameters with config\n",
    "wandb.config = {\"learning_rate\": 0.001, \"epochs\": 100, \"batch_size\": 128}\n",
    "\n",
    "# set up model and data\n",
    "model, dataloader = get_model(), get_data()\n",
    "\n",
    "# track gradients\n",
    "wandb.watch(model)\n",
    "\n",
    "for batch in dataloader:\n",
    "    metrics = model.training_step()\n",
    "    wandb.log(metrics)\n",
    "\n",
    "# save model at the end\n",
    "model.to_onnx()\n",
    "wandb.save(\"model.onnx\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0cf6c7",
   "metadata": {},
   "source": [
    "## Data loading and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f16b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-surf-10</strong> at: <a href='https://wandb.ai/shushankai/flower102/runs/875vd7pp' target=\"_blank\">https://wandb.ai/shushankai/flower102/runs/875vd7pp</a><br> View project at: <a href='https://wandb.ai/shushankai/flower102' target=\"_blank\">https://wandb.ai/shushankai/flower102</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_213841-875vd7pp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/shushanksingh/computer_vision/Exploration/wandb/run-20250805_213844-zuj3uehn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shushankai/flower102/runs/zuj3uehn' target=\"_blank\">whole-bush-11</a></strong> to <a href='https://wandb.ai/shushankai/flower102' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shushankai/flower102' target=\"_blank\">https://wandb.ai/shushankai/flower102</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shushankai/flower102/runs/zuj3uehn' target=\"_blank\">https://wandb.ai/shushankai/flower102/runs/zuj3uehn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shushankai/flower102/runs/zuj3uehn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7efdc4092e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_NAME = \"flower102\"\n",
    "\n",
    "wandb.init(\n",
    "    project=PROJECT_NAME\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1082fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flower_transform = transforms.Compose([\n",
    "    transforms.Resize([IMG_HEIGTH, IMG_WIDTH]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def get_data(train=True, subset=False, slice=5):\n",
    "    \n",
    "    path = \"Data/train/\" if train else \"Data/val/\"\n",
    "    split = \"train\" if train else \"val\"\n",
    "    \n",
    "    full_dataset = Flowers102(\n",
    "        root=path,\n",
    "        download= True, \n",
    "        transform= flower_transform, \n",
    "        split= split\n",
    "    )\n",
    "    if subset:\n",
    "        sub_dataset = torch.utils.data.Subset(\n",
    "            dataset=full_dataset, \n",
    "            indices=range(0, len(full_dataset), slice)\n",
    "        )\n",
    "    return sub_dataset if subset else full_dataset\n",
    "    \n",
    "\n",
    "def make_loader(dataset, batch_size):\n",
    "    loader = DataLoader(\n",
    "        dataset= dataset,\n",
    "        batch_size= batch_size,\n",
    "        shuffle= True, \n",
    "        num_workers= 2, \n",
    "        pin_memory= True\n",
    "    )\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38e27281",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a457b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will have 2 hidden layer neural netwrok \n",
    "class Modelv2(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_units ,bias=True, device=DEVICE):\n",
    "        super(Modelv2, self).__init__()\n",
    "        self.flaten = nn.Flatten()\n",
    "        self.layer_1 = nn.Linear(\n",
    "            in_features=in_features,\n",
    "            out_features= hidden_units, \n",
    "            bias= bias,\n",
    "            device= device\n",
    "        )\n",
    "        self.layer_2 = nn.Linear(\n",
    "            in_features=hidden_units,\n",
    "            out_features= out_features, \n",
    "            bias= bias,\n",
    "            device= device\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The below input is for only a single item from a batch\n",
    "        x = self.flaten(x)      Input: (224 ,224 ,3) -> Output: (224 * 224 * 3) \n",
    "        x = self.layer_1(x)     Input: (224 * 224 * 3) -> Output: hidden_units\n",
    "        x = self.relu(x)        Input: hidden_units -> Output: hidden_units\n",
    "        x = self.layer_2(x)     Input: hidden_units -> Output: 102 \n",
    "        \"\"\"\n",
    "        x = self.flaten(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9c761",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d59442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_log(loss, example_ct, epoch):\n",
    "    wandb.log({\"epoch\": epoch, \"loss\": loss, \"example_ct\": example_ct})\n",
    "    print(f\"Loss after {str(example_ct).zfill(5)} examples: {loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0222b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, config):\n",
    "    wandb.watch(\n",
    "        models= model,\n",
    "        criterion= criterion,\n",
    "        log='all',\n",
    "        log_freq= 10\n",
    "    )\n",
    "    \n",
    "    total_batches = len(loader) * config.epochs\n",
    "    example_ct = 0\n",
    "    batch_ct = 0\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        for _ , (images, labels) in enumerate(loader):\n",
    "            loss = train_batch(\n",
    "                x = images,\n",
    "                y = labels,\n",
    "                model = model,\n",
    "                loss = criterion,\n",
    "                optimizer = optimizer \n",
    "            )\n",
    "            example_ct += len(images)\n",
    "            batch_ct += 1\n",
    "            \n",
    "            if ((batch_ct + 1) % 25) == 0:\n",
    "                train_log(loss, example_ct, epoch)\n",
    "            \n",
    "\n",
    "def train_batch(x, y, model, optimizer, loss):\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    \n",
    "    outputs = model(x)\n",
    "    loss = loss(outputs, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f8f6a",
   "metadata": {},
   "source": [
    "## Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c75b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    # Make the data\n",
    "    train, val = get_data(train=True), get_data(train=False)\n",
    "    train_loader = make_loader(train,batch_size = config.batch_size)\n",
    "    val_loader = make_loader(val, batch_size = config.batch_size)\n",
    "    \n",
    "    # Make the model \n",
    "    model = Modelv2(\n",
    "        in_features= config.in_features,\n",
    "        out_features= config.out_features, \n",
    "        hidden_units= config.hidden_units,\n",
    "        device= DEVICE\n",
    "    )\n",
    "    \n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params= model.parameters(),\n",
    "        lr = config.learning_rate\n",
    "    )\n",
    "    \n",
    "    return model, train_loader, val_loader, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f4c787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "    with wandb.init(project=PROJECT_NAME, config=hyperparameters):\n",
    "        config = wandb.config\n",
    "        \n",
    "        model, train_loader, val_loader, criterion, optimizer = make(config)\n",
    "        print(model)\n",
    "        \n",
    "        train(model, train_loader, criterion, optimizer, config)\n",
    "        \n",
    "        # val(model, val_loader)\n",
    "        \n",
    "        return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df505d71",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array(Flowers102.classes)\n",
    "config = dict(\n",
    "    epochs = 20,\n",
    "    in_features = 3 * 224 * 224,\n",
    "    hidden_units = 64,\n",
    "    out_features = len(CLASS_NAMES),\n",
    "    learning_rate = 0.1,\n",
    "    batch_size = 16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f29a9bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/shushanksingh/computer_vision/Exploration/wandb/run-20250805_214427-sf9gqcy2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shushankai/flower102/runs/sf9gqcy2' target=\"_blank\">proud-voice-15</a></strong> to <a href='https://wandb.ai/shushankai/flower102' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shushankai/flower102' target=\"_blank\">https://wandb.ai/shushankai/flower102</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shushankai/flower102/runs/sf9gqcy2' target=\"_blank\">https://wandb.ai/shushankai/flower102/runs/sf9gqcy2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelv2(\n",
      "  (flaten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer_1): Linear(in_features=150528, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=102, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7892c29fbb334bfd9883c4da91ab2b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 00384 examples: 4.743\n",
      "Loss after 00784 examples: 4.817\n",
      "Loss after 01180 examples: 4.708\n",
      "Loss after 01580 examples: 4.691\n",
      "Loss after 01980 examples: 4.805\n",
      "Loss after 02376 examples: 4.561\n",
      "Loss after 02776 examples: 4.678\n",
      "Loss after 03172 examples: 4.631\n",
      "Loss after 03572 examples: 4.772\n",
      "Loss after 03972 examples: 4.758\n",
      "Loss after 04368 examples: 4.700\n",
      "Loss after 04768 examples: 4.770\n",
      "Loss after 05164 examples: 4.699\n",
      "Loss after 05564 examples: 4.668\n",
      "Loss after 05964 examples: 4.789\n",
      "Loss after 06360 examples: 4.590\n",
      "Loss after 06760 examples: 4.730\n",
      "Loss after 07156 examples: 4.575\n",
      "Loss after 07556 examples: 4.684\n",
      "Loss after 07956 examples: 4.659\n",
      "Loss after 08352 examples: 4.698\n",
      "Loss after 08752 examples: 4.657\n",
      "Loss after 09152 examples: 4.736\n",
      "Loss after 09548 examples: 4.659\n",
      "Loss after 09948 examples: 4.728\n",
      "Loss after 10344 examples: 4.637\n",
      "Loss after 10744 examples: 4.675\n",
      "Loss after 11144 examples: 4.724\n",
      "Loss after 11540 examples: 4.759\n",
      "Loss after 11940 examples: 4.774\n",
      "Loss after 12336 examples: 4.642\n",
      "Loss after 12736 examples: 4.784\n",
      "Loss after 13136 examples: 4.780\n",
      "Loss after 13532 examples: 4.766\n",
      "Loss after 13932 examples: 4.728\n",
      "Loss after 14328 examples: 4.700\n",
      "Loss after 14728 examples: 4.675\n",
      "Loss after 15128 examples: 4.765\n",
      "Loss after 15524 examples: 4.666\n",
      "Loss after 15924 examples: 4.778\n",
      "Loss after 16320 examples: 4.848\n",
      "Loss after 16720 examples: 4.596\n",
      "Loss after 17120 examples: 4.735\n",
      "Loss after 17516 examples: 4.661\n",
      "Loss after 17916 examples: 4.762\n",
      "Loss after 18316 examples: 4.700\n",
      "Loss after 18712 examples: 4.835\n",
      "Loss after 19112 examples: 4.711\n",
      "Loss after 19508 examples: 4.633\n",
      "Loss after 19908 examples: 4.810\n",
      "Loss after 20308 examples: 4.683\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>example_ct</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▅▇▄▄▇▄▂▆▆▄▄▃▆▁▁▃▄▃▅▃▃▄▆▃▆▆▅▄▄▆▆█▂▅▃▄█▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>example_ct</td><td>20308</td></tr><tr><td>loss</td><td>4.68267</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-voice-15</strong> at: <a href='https://wandb.ai/shushankai/flower102/runs/sf9gqcy2' target=\"_blank\">https://wandb.ai/shushankai/flower102/runs/sf9gqcy2</a><br> View project at: <a href='https://wandb.ai/shushankai/flower102' target=\"_blank\">https://wandb.ai/shushankai/flower102</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250805_214427-sf9gqcy2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model_pipeline(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece7393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23867af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eae3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e18c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22da0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
