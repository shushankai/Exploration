{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1d527b",
   "metadata": {},
   "source": [
    "# Building 2 hidden-layer nerual network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22657660",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfa815f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics \n",
    "import wandb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from  torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import Flowers102\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c9870",
   "metadata": {},
   "source": [
    "## CONFIGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "Project_name = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c22ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid',  # or 'random', 'bayes'\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'epochs': {'values': [5, 10]},\n",
    "        'batch_size': {'values': [8, 16]},\n",
    "        'img_height': {'values': [16, 32]},\n",
    "        'img_width': {'values': [16, 32]},\n",
    "        'learning_rate': {'values': [0.001, 0.0001]},\n",
    "        'hidden_units': {'values': [64, 128]}\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d526341",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=Project_name)\n",
    "config = wandb.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa1d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_HEIGTH = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "BATCH_SIZE = 16\n",
    "HIDDEN_UNITS = 64\n",
    "EPOCH = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12dd44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array(Flowers102.classes)\n",
    "CLASS_LEN = len(CLASS_NAMES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3cece0",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ded3ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_transform = transforms.Compose([\n",
    "    transforms.Resize([IMG_HEIGTH, IMG_WIDTH]),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bca56af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Flowers102(\n",
    "    root=\"Data/train/\",\n",
    "    download= True, \n",
    "    transform= flower_transform, \n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "val_dataset = Flowers102(\n",
    "    root=\"Data/eval/\",\n",
    "    download= True, \n",
    "    transform= flower_transform, \n",
    "    split=\"val\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "615a0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset= train_dataset, \n",
    "    batch_size= BATCH_SIZE , \n",
    "    num_workers= 0, \n",
    "    shuffle= True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset= val_dataset, \n",
    "    batch_size= BATCH_SIZE, \n",
    "    num_workers= 0, \n",
    "    shuffle= True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b9447",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dde1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4610b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will have 2 hidden layer neural netwrok \n",
    "class Modelv2(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_units ,bias=True, device=DEVICE):\n",
    "        super(Modelv2, self).__init__()\n",
    "        self.flaten = nn.Flatten()\n",
    "        self.layer_1 = nn.Linear(\n",
    "            in_features=in_features,\n",
    "            out_features= hidden_units, \n",
    "            bias= bias,\n",
    "            device= device\n",
    "        )\n",
    "        self.layer_2 = nn.Linear(\n",
    "            in_features=hidden_units,\n",
    "            out_features= out_features, \n",
    "            bias= bias,\n",
    "            device= device\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        The below input is for only a single item from a batch\n",
    "        x = self.flaten(x)      Input: (224 ,224 ,3) -> Output: (224 * 224 * 3) \n",
    "        x = self.layer_1(x)     Input: (224 * 224 * 3) -> Output: hidden_units\n",
    "        x = self.relu(x)        Input: hidden_units -> Output: hidden_units\n",
    "        x = self.layer_2(x)     Input: hidden_units -> Output: 102 \n",
    "        \"\"\"\n",
    "        x = self.flaten(x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9061c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelv2(\n",
       "  (flaten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (layer_1): Linear(in_features=150528, out_features=64, bias=True)\n",
       "  (layer_2): Linear(in_features=64, out_features=102, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Modelv2(\n",
    "    in_features= IMG_CHANNELS * IMG_HEIGTH * IMG_WIDTH,\n",
    "    out_features= len(CLASS_NAMES), \n",
    "    hidden_units= HIDDEN_UNITS\n",
    ")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8dfd2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=0.5)\n",
    "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=CLASS_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea4e5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:04<00:39,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.95280122756958\n",
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:08<00:34,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.977730751037598\n",
      "Epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:13<00:31,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.966175556182861\n",
      "Epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:17<00:27,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.95829439163208\n",
      "Epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:22<00:22,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.9807891845703125\n",
      "Epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:26<00:17,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.968995094299316\n",
      "Epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:30<00:13,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.951077461242676\n",
      "Epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:35<00:08,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.943302154541016\n",
      "Epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:39<00:04,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.953536510467529\n",
      "Epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:44<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss per batch: 4.977957725524902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCH)):\n",
    "    model.train()\n",
    "    loss_per_batch = []\n",
    "    print(f\"Epoch: {epoch}/{EPOCH}\")\n",
    "    for img, label in train_loader:\n",
    "        # load the data in DEVICE avliable\n",
    "        img, label = img.to(DEVICE), label.to(DEVICE)\n",
    "        \n",
    "        logits = model(img)\n",
    "        # print(torch.exp(logits)[2])\n",
    "        # print(torch.exp(logits).sum(dim=1).unsqueeze(1))\n",
    "        # print(torch.exp(logits).shape)\n",
    "        # probs = torch.exp(logits) / torch.exp(logits).sum(dim=1).unsqueeze(1)\n",
    "        # print(probs[0])\n",
    "        # print(torch.softmax(logits, dim=1)[0])\n",
    "        loss = loss_fn(logits, label)\n",
    "        loss_per_batch.append(loss)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    avg_loss = sum(loss_per_batch)/len(loss_per_batch)\n",
    "    print(f\"Average loss per batch: {avg_loss}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f034363",
   "metadata": {},
   "source": [
    "we are using cross entropy loss. The cross entropy loss helps us in imporving the probability assigned to the correct label \n",
    "in pytorch cross entropy use softmax to convert the logits to probabilities \n",
    "\n",
    "Softmax : e**logits_at_i/ sum(e**logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6344e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom shape = [16] -> this should broadcast to 16, 102\n",
    "# uper shape = [16, 102]\n",
    "\n",
    "# for sum operation \n",
    "# input tensor -> 16, 102\n",
    "# if we do a sum along the dim = 1 then all the values which are 102 in every row will be added \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
